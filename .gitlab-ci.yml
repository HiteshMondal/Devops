# .gitlab-ci.yml - GitLab CI/CD Pipeline Configuration

# Global variables
variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  DOCKER_IMAGE: "${CI_REGISTRY_IMAGE}:${CI_COMMIT_SHORT_SHA}"
  DOCKER_IMAGE_LATEST: "${CI_REGISTRY_IMAGE}:latest"
  KUBE_NAMESPACE: "devops-demo"
  AWS_REGION: "us-east-1"
  TERRAFORM_VERSION: "1.5.0"
  KUBECTL_VERSION: "1.28.0"
  HELM_VERSION: "3.12.0"

# Stages definition
stages:
  - build
  - test
  - security
  - package
  - deploy-staging
  - test-staging
  - deploy-production
  - rollback

# Cache configuration
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - node_modules/
    - .terraform/
    - .cache/

# Templates
.docker_template: &docker_definition
  image: docker:latest
  services:
    - docker:dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY

.kubectl_template: &kubectl_definition
  image: bitnami/kubectl:${KUBECTL_VERSION}
  before_script:
    - echo "$KUBE_CONFIG" | base64 -d > /tmp/kubeconfig
    - export KUBECONFIG=/tmp/kubeconfig

.terraform_template: &terraform_definition
  image: hashicorp/terraform:${TERRAFORM_VERSION}
  before_script:
    - terraform --version
    - cd terraform/
    - terraform init

# Build Stage
build:app:
  stage: build
  image: node:18-alpine
  script:
    - echo "Building application..."
    - npm ci --only=production || echo "No npm dependencies"
    - |
      cat > build-info.json <<EOF
      {
        "version": "${CI_COMMIT_SHORT_SHA}",
        "branch": "${CI_COMMIT_REF_NAME}",
        "build_number": "${CI_PIPELINE_ID}",
        "build_time": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
      }
      EOF
  artifacts:
    paths:
      - index.html
      - build-info.json
    expire_in: 1 week
  only:
    - branches
    - tags

# Test Stage
test:lint:
  stage: test
  image: node:18-alpine
  script:
    - npm install -g htmlhint csslint jshint
    - htmlhint index.html || true
    - csslint styles.css || true
    - jshint script.js || true
  allow_failure: true
  only:
    - merge_requests
    - main

test:unit:
  stage: test
  image: node:18-alpine
  script:
    - echo "Running unit tests..."
    - npm test || echo "No tests configured"
  coverage: '/Coverage: \d+\.\d+%/'
  only:
    - merge_requests
    - main

test:integration:
  stage: test
  <<: *docker_definition
  script:
    - docker build -t test-image .
    - docker run -d --name test-container -p 8080:8080 test-image
    - sleep 5
    - docker exec test-container curl -f http://localhost:8080/health
    - docker stop test-container
    - docker rm test-container
  only:
    - merge_requests
    - main

# Security Stage
security:sast:
  stage: security
  image: 
    name: semgrep/semgrep:latest
    entrypoint: [""]
  script:
    - semgrep --config=auto --json -o sast-report.json .
  artifacts:
    reports:
      sast: sast-report.json
    expire_in: 1 week
  only:
    - main
    - merge_requests

security:container:
  stage: security
  image:
    name: aquasec/trivy:latest
    entrypoint: [""]
  script:
    - trivy fs --security-checks vuln,config --format json -o container-scan.json .
    - trivy fs --security-checks vuln,config .
  artifacts:
    reports:
      container_scanning: container-scan.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
    - merge_requests

security:dependency:
  stage: security
  image: owasp/dependency-check:latest
  script:
    - |
      /usr/share/dependency-check/bin/dependency-check.sh \
        --scan . \
        --format JSON \
        --out dependency-check-report.json \
        --prettyPrint
  artifacts:
    reports:
      dependency_scanning: dependency-check-report.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
    - merge_requests

# Package Stage
package:docker:
  stage: package
  <<: *docker_definition
  script:
    - echo "Building Docker image..."
    - docker build -t $DOCKER_IMAGE -t $DOCKER_IMAGE_LATEST .
    - echo "Pushing to GitLab Container Registry..."
    - docker push $DOCKER_IMAGE
    - docker push $DOCKER_IMAGE_LATEST
  only:
    - main
    - tags

package:helm:
  stage: package
  image: alpine/helm:${HELM_VERSION}
  script:
    - helm package ./helm/webapp-chart
    - helm repo index .
  artifacts:
    paths:
      - "*.tgz"
      - index.yaml
    expire_in: 1 month
  only:
    - main
    - tags

# Deploy to Staging
deploy:staging:terraform:
  stage: deploy-staging
  <<: *terraform_definition
  environment:
    name: staging
    url: https://staging.example.com
  script:
    - terraform workspace select staging || terraform workspace new staging
    - terraform plan -var="environment=staging" -out=tfplan
    - terraform apply -auto-approve tfplan
  only:
    - main
  when: manual

deploy:staging:kubernetes:
  stage: deploy-staging
  <<: *kubectl_definition
  environment:
    name: staging
    url: https://staging.example.com
    on_stop: cleanup:staging
  script:
    - kubectl create namespace ${KUBE_NAMESPACE}-staging --dry-run=client -o yaml | kubectl apply -f -
    - |
      kubectl apply -n ${KUBE_NAMESPACE}-staging -f - <<EOF
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: app-version
      data:
        version: "${CI_COMMIT_SHORT_SHA}"
        pipeline: "${CI_PIPELINE_ID}"
        branch: "${CI_COMMIT_REF_NAME}"
      EOF
    - kubectl set image deployment/webapp-deployment webapp=$DOCKER_IMAGE -n ${KUBE_NAMESPACE}-staging
    - kubectl rollout status deployment/webapp-deployment -n ${KUBE_NAMESPACE}-staging
  only:
    - main
  needs:
    - package:docker

# Test Staging Environment
test:staging:smoke:
  stage: test-staging
  image: curlimages/curl:latest
  environment:
    name: staging
  script:
    - |
      STAGING_URL="https://staging.example.com"
      echo "Testing staging environment at ${STAGING_URL}"
      curl -f ${STAGING_URL}/health || exit 1
      curl -f ${STAGING_URL} || exit 1
  only:
    - main
  needs:
    - deploy:staging:kubernetes

test:staging:performance:
  stage: test-staging
  image: grafana/k6:latest
  environment:
    name: staging
  script:
    - |
      cat > load-test.js <<EOF
      import http from 'k6/http';
      import { check, sleep } from 'k6';
      
      export let options = {
        stages: [
          { duration: '2m', target: 100 },
          { duration: '5m', target: 100 },
          { duration: '2m', target: 0 },
        ],
        thresholds: {
          http_req_duration: ['p(95)<500'],
          http_req_failed: ['rate<0.1'],
        },
      };
      
      export default function() {
        let response = http.get('https://staging.example.com');
        check(response, {
          'status is 200': (r) => r.status === 200,
          'response time < 500ms': (r) => r.timings.duration < 500,
        });
        sleep(1);
      }
      EOF
    - k6 run load-test.js
  artifacts:
    reports:
      performance: k6-report.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
  needs:
    - test:staging:smoke

# Deploy to Production
deploy:production:approval:
  stage: deploy-production
  image: alpine:latest
  script:
    - echo "Waiting for manual approval..."
  environment:
    name: production
    url: https://production.example.com
  when: manual
  only:
    - main
    - tags
  needs:
    - test:staging:smoke

deploy:production:terraform:
  stage: deploy-production
  <<: *terraform_definition
  environment:
    name: production
    url: https://production.example.com
  script:
    - terraform workspace select production || terraform workspace new production
    - terraform plan -var="environment=production" -out=tfplan
    - terraform apply -auto-approve tfplan
  only:
    - main
    - tags
  needs:
    - deploy:production:approval

deploy:production:blue-green:
  stage: deploy-production
  <<: *kubectl_definition
  environment:
    name: production
    url: https://production.example.com
    on_stop: cleanup:production
  script:
    - |
      echo "Starting Blue-Green deployment..."
      
      # Check current active version (blue or green)
      CURRENT_VERSION=$(kubectl get service webapp-service -n ${KUBE_NAMESPACE} -o jsonpath='{.spec.selector.version}' || echo "blue")
      
      if [ "$CURRENT_VERSION" = "blue" ]; then
        NEW_VERSION="green"
      else
        NEW_VERSION="blue"
      fi
      
      echo "Current version: $CURRENT_VERSION, deploying to: $NEW_VERSION"
      
      # Deploy to inactive version
      kubectl apply -n ${KUBE_NAMESPACE} -f - <<EOF
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: webapp-deployment-${NEW_VERSION}
        labels:
          version: ${NEW_VERSION}
      spec:
        replicas: 3
        selector:
          matchLabels:
            app: webapp
            version: ${NEW_VERSION}
        template:
          metadata:
            labels:
              app: webapp
              version: ${NEW_VERSION}
            annotations:
              prometheus.io/scrape: "true"
              prometheus.io/port: "8080"
          spec:
            containers:
            - name: webapp
              image: ${DOCKER_IMAGE}
              ports:
              - containerPort: 8080
              resources:
                requests:
                  memory: "64Mi"
                  cpu: "100m"
                limits:
                  memory: "256Mi"
                  cpu: "500m"
              livenessProbe:
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 10
              readinessProbe:
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 5
                periodSeconds: 5
      EOF
      
      # Wait for new version to be ready
      kubectl rollout status deployment/webapp-deployment-${NEW_VERSION} -n ${KUBE_NAMESPACE}
      
      # Run smoke test on new version
      POD_NAME=$(kubectl get pods -n ${KUBE_NAMESPACE} -l version=${NEW_VERSION} -o jsonpath='{.items[0].metadata.name}')
      kubectl exec -n ${KUBE_NAMESPACE} $POD_NAME -- curl -f http://localhost:8080/health
      
      # Switch traffic to new version
      kubectl patch service webapp-service -n ${KUBE_NAMESPACE} -p '{"spec":{"selector":{"version":"'${NEW_VERSION}'"}}}'
      
      echo "Traffic switched to ${NEW_VERSION}"
      
      # Keep old version for quick rollback
      echo "Old version ${CURRENT_VERSION} kept for rollback"
      
      # Store deployment info for rollback
      kubectl create configmap deployment-info \
        --from-literal=previous-version=${CURRENT_VERSION} \
        --from-literal=current-version=${NEW_VERSION} \
        --from-literal=image=${DOCKER_IMAGE} \
        --from-literal=timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
        -n ${KUBE_NAMESPACE} \
        --dry-run=client -o yaml | kubectl apply -f -
  only:
    - main
    - tags
  needs:
    - deploy:production:approval
    - deploy:production:terraform

deploy:production:canary:
  stage: deploy-production
  <<: *kubectl_definition
  environment:
    name: production-canary
    url: https://canary.production.example.com
  script:
    - |
      echo "Starting Canary deployment..."
      
      # Deploy canary version (10% traffic)
      kubectl apply -n ${KUBE_NAMESPACE} -f - <<EOF
      apiVersion: v1
      kind: Service
      metadata:
        name: webapp-service-canary
      spec:
        selector:
          app: webapp
          version: canary
        ports:
        - port: 80
          targetPort: 8080
      ---
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: webapp-deployment-canary
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: webapp
            version: canary
        template:
          metadata:
            labels:
              app: webapp
              version: canary
          spec:
            containers:
            - name: webapp
              image: ${DOCKER_IMAGE}
              ports:
              - containerPort: 8080
      EOF
      
      kubectl rollout status deployment/webapp-deployment-canary -n ${KUBE_NAMESPACE}
      
      echo "Canary deployment complete. Monitor metrics before full rollout."
  when: manual
  only:
    - main
  allow_failure: true

# Rollback Stage
rollback:production:
  stage: rollback
  <<: *kubectl_definition
  environment:
    name: production
  script:
    - |
      echo "Starting rollback..."
      
      # Get previous version from configmap
      CURRENT_VERSION=$(kubectl get configmap deployment-info -n ${KUBE_NAMESPACE} -o jsonpath='{.data.current-version}')
      PREVIOUS_VERSION=$(kubectl get configmap deployment-info -n ${KUBE_NAMESPACE} -o jsonpath='{.data.previous-version}')
      
      echo "Rolling back from ${CURRENT_VERSION} to ${PREVIOUS_VERSION}"
      
      # Switch traffic back to previous version
      kubectl patch service webapp-service -n ${KUBE_NAMESPACE} -p '{"spec":{"selector":{"version":"'${PREVIOUS_VERSION}'"}}}'
      
      # Delete failed version
      kubectl delete deployment webapp-deployment-${CURRENT_VERSION} -n ${KUBE_NAMESPACE}
      
      echo "Rollback complete"
  when: manual
  only:
    - main
    - tags

# Cleanup jobs
cleanup:staging:
  stage: .post
  <<: *kubectl_definition
  environment:
    name: staging
    action: stop
  script:
    - kubectl delete namespace ${KUBE_NAMESPACE}-staging --ignore-not-found=true
  when: manual
  only:
    - main

cleanup:production:
  stage: .post
  <<: *kubectl_definition
  environment:
    name: production
    action: stop
  script:
    - echo "Production cleanup must be done manually for safety"
  when: manual
  only:
    - main

# Notification job
notify:slack:
  stage: .post
  image: curlimages/curl:latest
  script:
    - |
      if [ "$CI_JOB_STATUS" = "success" ]; then
        STATUS_EMOJI="✅"
        COLOR="good"
      else
        STATUS_EMOJI="❌"
        COLOR="danger"
      fi
      
      curl -X POST -H 'Content-type: application/json' \
        --data "{
          \"attachments\": [{
            \"color\": \"${COLOR}\",
            \"title\": \"${STATUS_EMOJI} Pipeline ${CI_PIPELINE_ID} - ${CI_JOB_STATUS}\",
            \"text\": \"Project: ${CI_PROJECT_NAME}\nBranch: ${CI_COMMIT_REF_NAME}\nCommit: ${CI_COMMIT_SHORT_SHA}\nAuthor: ${GITLAB_USER_NAME}\",
            \"footer\": \"GitLab CI\",
            \"footer_icon\": \"https://about.gitlab.com/images/press/logo/png/gitlab-icon-rgb.png\",
            \"ts\": $(date +%s)
          }]
        }" \
        ${SLACK_WEBHOOK_URL}
  when: always
  only:
    variables:
      - $SLACK_WEBHOOK_URL